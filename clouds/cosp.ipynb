{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a43ed7-7624-4da9-b213-32f892574a65",
   "metadata": {},
   "source": [
    "# Unified MDTF/GFDL/NCAR Analysis Notebook Template\n",
    "\n",
    "More details on the development process:\n",
    "[MDTF Planning Document](https://docs.google.com/document/d/1P8HqL8O5304qwR3ik9RmgFDwSWwlkPgOjnp39PIkLfY/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67185bc-4731-4c89-b63a-ca8953428f07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Development mode: constantly refreshes module code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898886b-b5e1-4de0-939a-f715748be915",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Framework Code and Diagnostic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4168ea13-0a51-4f50-b0ae-8cccbd75161b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from esnb import NotebookDiagnostic, RequestedVariable, CaseGroup2\n",
    "from esnb.sites.gfdl import call_dmget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c032af57-fd94-4af8-997e-09195a7dd27c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 315 ms, total: 32.9 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define a mode (leave \"prod\" for now)\n",
    "mode = \"prod\"\n",
    "\n",
    "# Verbosity\n",
    "verbose = True\n",
    "\n",
    "cosp_on = True\n",
    "# Give your diagnostic a name and a short description\n",
    "diag_name = \"clouds\"\n",
    "diag_desc = \"cloud diganostics using model outputs and cosp simulator\"\n",
    "\n",
    "# Define what variables you would like to analyze. The first entry is the\n",
    "# variable name and the second entry is the realm (post-processing dir).\n",
    "#   (By default, monthly timeseries data will be loaded. TODO: add documentation\n",
    "#    on how to select different frequencies, multiple realms to search, etc.)\n",
    "variables = [\n",
    "    RequestedVariable(\"IWP\", \"atmos\"),\n",
    "    RequestedVariable(\"LWP\", \"atmos\"),\n",
    "    RequestedVariable(\"low_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"high_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"mid_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"olr\", \"atmos\"),\n",
    "    RequestedVariable(\"olr_clr\", \"atmos\"),\n",
    "    RequestedVariable(\"lwdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"lwdn_sfc_clr\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_toa\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_toa_clr\", \"atmos\"),\n",
    "    RequestedVariable(\"swdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"swdn_sfc_clr\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_sfc_clr\", \"atmos\"),\n",
    "    #RequestedVariable(\"reff_modis\", \"atmos\"),\n",
    "]\n",
    "\n",
    "if cosp_on:\n",
    "    variables.extend([\n",
    "        #RequestedVariable(\"tauctpmodis_1\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_2\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_3\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_4\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_5\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_6\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        #RequestedVariable(\"tauctpmodis_7\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ctpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"lwpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"iwpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"locldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"hicldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"mdcldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"lremodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"iremodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ttaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ltaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"itaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"tlogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"llogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ilogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "    ])\n",
    "\n",
    "\n",
    "# Initialize the diagnostic with its name, description, vars, and options\n",
    "diag = NotebookDiagnostic(diag_name, diag_desc, variables=variables)\n",
    "\n",
    "# Define the groups of experiments to analyze. Provide a single dora id for one experiment\n",
    "# or a list of IDs to aggregate multiple experiments into one; e.g. historical+future runs\n",
    "# dora id: cm5-9\n",
    "groups = [\n",
    "    CaseGroup2(\"3302\", name=\"am5d11_amip_cosp_sphere\", date_range=(\"2001-01-01\", \"2020-12-31\")),\n",
    "    CaseGroup2(\"3296\", name=\"am5d11_amip_cosp\", date_range=(\"2001-01-01\", \"2020-12-31\")),\n",
    "    CaseGroup2(\"3101\", name=\"am4mg2_cosp\", date_range=(\"2001-01-01\", \"2020-12-31\")),\n",
    "    #CaseGroup2(\"2916\",date_range=(\"0101-01-01\", \"0149-12-31\")),\n",
    "    #CaseGroup2(\"3031\",date_range=(\"0101-01-01\", \"0149-12-31\")),\n",
    "    #CaseGroup2(\"2198\",date_range=(\"0101-01-01\", \"0149-12-31\")),\n",
    "    #CaseGroup2(\"esm45-109\",date_range=(\"0101-01-01\", \"0149-12-31\")),\n",
    "    #CaseGroup2(\"895\",date_range=(\"0101-01-01\",  \"0149-12-31\")),\n",
    "]\n",
    "shorttitle = [\"AM5_D11_sphere\",\"AM5_D11\",\"AM4MG2\"]#\"OM4_D5\", \"B11_D6\", \"CM4X\", \"B11_ESM4.5\", \"CM4\"]\n",
    "\n",
    "ref_id = 2 # the experiment that used as the control run to be compared with\n",
    "\n",
    "# Combine the experiments with the diag request and determine what files need to be loaded:\n",
    "diag.resolve(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecd8b9-d851-4b9b-8032-ac8b77deb511",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "stop_here"
    ]
   },
   "source": [
    "<i>(The files above are necessary to run the diagnostic.)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e173eb4-5c69-40b7-87a6-2c62d1111162",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmget: All files are online\n",
      "[CaseGroup am5d11_amip_cosp_sphere <>  resolved=True  loaded=True, CaseGroup am5d11_amip_cosp <>  resolved=True  loaded=True, CaseGroup am4mg2_cosp <>  resolved=True  loaded=True]\n"
     ]
    }
   ],
   "source": [
    "# Check to see the dmget status before calling \"open\"\n",
    "call_dmget(diag.files,status=True)\n",
    "# Load the data as xarray datasets\n",
    "diag.open()\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b55151-a102-41f6-b54d-3087c0e45efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs \n",
    "import numpy as np\n",
    "from numpy import ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690fd131-8cd2-418b-922c-526e40d594b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    name = var.varname\n",
    "    if name.endswith(\"_clr\"): # process clear-sky variables\n",
    "        base_name = name[:-4]  # strip \"_clr\"\n",
    "        # only if the clear-sky partner has a corresponding all-sky variable\n",
    "        if any(v.varname == base_name for v in variables):\n",
    "            cld_name = f\"{base_name}_cld\"\n",
    "            # compute difference and save into each group's dataset\n",
    "            for group in groups:\n",
    "                allsky = group.datasets[RequestedVariable(base_name, \"atmos\")][base_name]\n",
    "                clearsky = group.datasets[var][var.varname]\n",
    "                new_var = RequestedVariable(cld_name, \"atmos\")\n",
    "                # assign\n",
    "                group.datasets[RequestedVariable(base_name, \"atmos\")][cld_name] = allsky - clearsky\n",
    "if cosp_on:\n",
    "    variables_plot = [\n",
    "    RequestedVariable(\"IWP\", \"atmos\"),\n",
    "    RequestedVariable(\"LWP\", \"atmos\"),\n",
    "    RequestedVariable(\"low_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"high_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"mid_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"olr\", \"atmos\"),\n",
    "    RequestedVariable(\"lwdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_toa\", \"atmos\"),\n",
    "    RequestedVariable(\"swdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"ctpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"lwpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"iwpmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"locldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"hicldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"mdcldmodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"lremodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"iremodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ttaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ltaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"itaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"tlogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"llogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),\n",
    "        RequestedVariable(\"ilogtaumodis\", [\"atmos_modis\", \"atmos_cosp\"]),]\n",
    "else:\n",
    "    variables_plot = [\n",
    "    RequestedVariable(\"IWP\", \"atmos\"),\n",
    "    RequestedVariable(\"LWP\", \"atmos\"),\n",
    "    RequestedVariable(\"low_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"high_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"mid_cld_amt\", \"atmos\"),\n",
    "    RequestedVariable(\"olr\", \"atmos\"),\n",
    "    RequestedVariable(\"lwdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_toa\", \"atmos\"),\n",
    "    RequestedVariable(\"swdn_sfc\", \"atmos\"),\n",
    "    #RequestedVariable(\"swup_sfc\", \"atmos\"),\n",
    "]\n",
    "var_rad = [RequestedVariable(\"olr\", \"atmos\"),\n",
    "    RequestedVariable(\"lwdn_sfc\", \"atmos\"),\n",
    "    RequestedVariable(\"swup_toa\", \"atmos\"),\n",
    "    RequestedVariable(\"swdn_sfc\", \"atmos\"),\n",
    "    #RequestedVariable(\"swup_sfc\", \"atmos\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Always included variables\n",
    "vars = [\"LWP\", \"IWP\", \"low_cld_amt\", \"high_cld_amt\", \"mid_cld_amt\"]\n",
    "longnames = [\n",
    "    \"Liquid Water Path\",\n",
    "    \"Ice Water Path\",\n",
    "    \"Low-Level Cloud Fraction\",\n",
    "    \"High-Level Cloud Fraction\",\n",
    "    \"Mid-Level Cloud Fraction\",\n",
    "]\n",
    "\n",
    "# Add MODIS-related variables only if cosp_on\n",
    "if cosp_on:\n",
    "    vars.extend([\n",
    "        \"locldmodis\", \"hicldmodis\", \"mdcldmodis\", \"cldfrac\", \"ctpmodis\", \"reff_modis\",\n",
    "        \"lremodis\", \"iremodis\", \"ttaumodis\", \"ltaumodis\", \"itaumodis\",\n",
    "        \"tlogtaumodis\", \"llogtaumodis\", \"ilogtaumodis\"\n",
    "    ])\n",
    "    \n",
    "    longnames.extend([\n",
    "        \"COSPMODIS Low-Level Cloud Fraction\",\n",
    "        \"COSPMODIS High-Level Cloud Fraction\",\n",
    "        \"COSPMODIS Mid-Level Cloud Fraction\",\n",
    "        \"COSPMODIS Total Cloud Fraction\",\n",
    "        \"COSPMODIS Cloud Top Pressure\",\n",
    "        \"MODIS Effective Radius\",\n",
    "        \"COSPMODIS Liquid Effective Radius\",\n",
    "        \"COSPMODIS Ice Effective Radius\",\n",
    "        \"COSPMODIS Total Cloud Optical Depth\",\n",
    "        \"COSPMODIS Liquid Cloud Optical Depth\",\n",
    "        \"COSPMODIS Ice Cloud Optical Depth\",\n",
    "        \"COSPMODIS Log of Total Cloud Optical Depth\",\n",
    "        \"COSPMODIS Log of Liquid Cloud Optical Depth\",\n",
    "        \"COSPMODIS Log of Ice Cloud Optical Depth\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf83d81b-54fd-460e-983b-a0019d95d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "# Open dataset\n",
    "ds = xr.open_dataset(\"/work/rjk/data/CERES/EBAF-All/CERES_EBAF_Ed4.2.1_Subset_200003-202412.nc\")\n",
    "ds_ceres = xr.Dataset({\n",
    "        'lat': (['lat'], groups[0].datasets[diag.variables[0]]['lat'].values),\n",
    "        'lon': (['lon'], groups[0].datasets[diag.variables[0]]['lon'].values),\n",
    "    })\n",
    "regridder = xe.Regridder(ds, ds_ceres, method='bilinear', periodic=True)\n",
    "ds_ceres[\"olr_cld\"]=-regridder(ds[\"toa_cre_lw_mon\"])\n",
    "ds_ceres[\"swup_toa_cld\"]=-regridder(ds[\"toa_cre_sw_mon\"])\n",
    "ds_ceres[\"lwdn_sfc_cld\"]=regridder(ds[\"sfc_cre_net_lw_mon\"])\n",
    "ds_ceres[\"swdn_sfc_cld\"]=regridder(ds[\"sfc_sw_down_all_mon\"]) - regridder(ds[\"sfc_sw_down_clr_t_mon\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72491649-302d-4d67-9ceb-0b17f98e0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vftmp/Jing.Feng/pid1733046/ipykernel_1737630/1463951860.py:34: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# global-mean seasonal cycle\n",
    "shorttitle = [\"AM5_D11_sphere\",\"AM5_D11\",\"AM4MG2\"]\n",
    "\n",
    "panel_colors = [\"orange\", \"green\", \"grey\", \"blue\",\"black\"]\n",
    "from cosp_lib import cal_gbl_mean, monthly_mean\n",
    "\n",
    "n_vars = len(variables_plot)\n",
    "n_cols = math.ceil(math.sqrt(n_vars))\n",
    "n_rows = math.ceil(n_vars / n_cols)\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 12))\n",
    "for i, var in enumerate(variables_plot):\n",
    "    fig.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.95)\n",
    "    ax=axs.flat[i]\n",
    "    if var in var_rad:\n",
    "        varname = f\"{var}_cld\"\n",
    "    else:\n",
    "        varname = var.varname\n",
    "        \n",
    "    for n,group in enumerate(groups):\n",
    "        ds = group.datasets[var]\n",
    "        monthly_clim = monthly_mean(ds, varname)\n",
    "        ax.plot(np.arange(1, 13), monthly_clim.values, label=shorttitle[n],color=panel_colors[n])\n",
    "        std_dev = monthly_clim.std(dim='month').values\n",
    "        group.add_metric(var.varname, (\"seasonal std\", float(std_dev)))\n",
    "        \n",
    "        ax.set_title(f\"{varname} [{ds[var.varname].units}]\", fontsize=16)\n",
    "    ax.set_xlabel(\"Month\")\n",
    "    ax.set_ylabel(f\"{varname} [{ds[var.varname].units}]\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"seasonal.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce7601-7614-470f-9241-62bf5e176066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zonal-mean\n",
    "\n",
    "from cosp_lib import zonal_mean\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 12))\n",
    "for i, var in enumerate(variables_plot):\n",
    "    fig.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.95)\n",
    "    ax=axs.flat[i]\n",
    "    if var in var_rad:\n",
    "        varname = f\"{var}_cld\"\n",
    "    else:\n",
    "        varname = var.varname\n",
    "        \n",
    "    for n,group in enumerate(groups):\n",
    "        ds = group.datasets[var]\n",
    "        zonal_clim = zonal_mean(ds, varname)\n",
    "        ax.plot(zonal_clim.values,ds['lat'], label=shorttitle[n],color=panel_colors[n])\n",
    "        std_dev = zonal_clim.std(dim='lat').values\n",
    "        group.add_metric(var.varname, (\"zonal std\", float(std_dev)))\n",
    "        \n",
    "        ax.set_title(f\"{varname} [{ds[var.varname].units}]\", fontsize=16)\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.set_xlabel(f\"{varname} [{ds[var.varname].units}]\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"zonal.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065df712-1a44-4f7f-830d-3fea545b5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global-mean time series\n",
    "\n",
    "for var in variables_plot:\n",
    "    if var in var_rad:\n",
    "        varname = f\"{var}_cld\"\n",
    "    else:\n",
    "        varname = var.varname\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    fig.subplots_adjust(top=0.95, bottom=0.1, left=0.1, right=0.95)\n",
    "\n",
    "    for group in groups:\n",
    "        ds = group.datasets[var]\n",
    "        gbl_mean_time = cal_gbl_mean(ds, varname)\n",
    "        rolled = gbl_mean_time.rolling(time=12, center=True, min_periods=1).construct('window_dim').mean('window_dim')\n",
    "        ax.plot(ds['time'], rolled.values, label=group)\n",
    "\n",
    "    ax.set_title(f\"Global Mean Time Series, {varname}, {ds[var.varname].units}\", fontsize=16)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(f\"{varname} [{ds[var.varname].units}]\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig(f\"{varname}.ts.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9958fa-b439-417c-bc99-6a5918abeba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# spatial map differences to a control-run (global, arctic, antarctic)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"cartopy.io\")\n",
    "\n",
    "views = {\n",
    "    \"global\": {\n",
    "        \"proj\": ccrs.Robinson(central_longitude=-180),\n",
    "        \"extent\": None\n",
    "    },\n",
    "    \"arctic\": {\n",
    "        \"proj\": ccrs.NorthPolarStereo(),\n",
    "        \"extent\": [-180, 180, 60, 90]\n",
    "    },\n",
    "    \"antarctic\": {\n",
    "        \"proj\": ccrs.SouthPolarStereo(),\n",
    "        \"extent\": [-180, 180, -90, -60]\n",
    "    }\n",
    "}\n",
    "\n",
    "coastline = cfeature.NaturalEarthFeature(\n",
    "    category='physical', name='coastline',\n",
    "    scale='110m', facecolor='none')\n",
    "\n",
    "for var in variables_plot:\n",
    "\n",
    "    # Reference data and grid\n",
    "    if var in var_rad:\n",
    "        varname = f\"{var}_cld\"\n",
    "    else:\n",
    "        varname = var.varname\n",
    "        \n",
    "    ref_ds = groups[ref_id].datasets[var]\n",
    "    ref_data = ref_ds[varname].mean(dim='time')\n",
    "    lon_ref = ref_ds['lon']\n",
    "    lat_ref = ref_ds['lat']\n",
    "\n",
    "    # Precompute all differences on the reference grid once\n",
    "    all_diffs = []\n",
    "    for group in groups[:-1]:\n",
    "        model_ds = group.datasets[var]\n",
    "        model_data = model_ds[varname].mean(dim='time')\n",
    "        try:\n",
    "            # Regrid to reference grid\n",
    "            model_interp = model_data.interp(lon=lon_ref, lat=lat_ref)\n",
    "            diff = model_interp - ref_data\n",
    "            all_diffs.append(diff)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Interpolation failed for {group.name}: {e}\")\n",
    "            all_diffs.append(None)\n",
    "\n",
    "    # Prepare color scale based on all diffs\n",
    "    valid_diffs = [d for d in all_diffs if d is not None and np.any(np.isfinite(d.values))]\n",
    "    if not valid_diffs:\n",
    "        print(f\"[Warning] No valid data for {var.varname}. Skipping plots.\")\n",
    "        continue\n",
    "\n",
    "    all_values = np.concatenate([d.values.flatten() for d in valid_diffs])\n",
    "    if np.percentile(all_values,95) * np.percentile(all_values,5) <0:\n",
    "        vmax = np.percentile(abs(all_values),95)\n",
    "        vmin = -vmax\n",
    "    else:\n",
    "        vmax = max([0,np.percentile(all_values,95)])\n",
    "        vmin = min([0,np.percentile(all_values,5)])\n",
    "        \n",
    "    cmap = 'RdBu_r'\n",
    "\n",
    "    for view_name, view_cfg in views.items():\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(14, 8),\n",
    "                                subplot_kw={'projection': view_cfg['proj']})\n",
    "        fig.subplots_adjust(wspace=0.05, hspace=0.15, top=0.9, bottom=0.1)\n",
    "    \n",
    "        for n, diff in enumerate(all_diffs):\n",
    "            row, col = divmod(n, 2)\n",
    "            ax = axs[row, col]\n",
    "    \n",
    "            if diff is None or not np.any(np.isfinite(diff.values)):\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            lat_weights = np.cos(np.deg2rad(model_ds['lat']))\n",
    "            lat_weights.name = \"weights\"\n",
    "            # Expand lat_weights to 2D (lat, lon) by broadcasting\n",
    "            weights_2d = xr.broadcast(lat_weights, model_ds['lon'])[0]\n",
    "            # Apply weights and compute mean\n",
    "\n",
    "            mesh = ax.pcolormesh(lon_ref, lat_ref, diff,\n",
    "                                 vmin=vmin, vmax=vmax,\n",
    "                                 transform=ccrs.PlateCarree(),\n",
    "                                 cmap=cmap, shading=\"nearest\")\n",
    "            ax.set_title(f\"({chr(97 + n)}) {shorttitle[n]} – {shorttitle[ref_id]}\", fontsize=11)\n",
    "    \n",
    "            ax.coastlines()\n",
    "            if view_cfg['extent']:\n",
    "                ax.set_extent(view_cfg['extent'], crs=ccrs.PlateCarree())\n",
    "            else:\n",
    "                ax.set_global()\n",
    "    \n",
    "            if isinstance(view_cfg['proj'], (ccrs.NorthPolarStereo, ccrs.SouthPolarStereo)):\n",
    "                # Add circular boundary to polar plots\n",
    "                theta = np.linspace(0, 2 * np.pi, 100)\n",
    "                center = np.array([0.5, 0.5])\n",
    "                radius = 0.5\n",
    "                verts = np.vstack([np.sin(theta), np.cos(theta)]).T * radius + center\n",
    "                circle_path = Path(verts)\n",
    "                ax.set_boundary(circle_path, transform=ax.transAxes)\n",
    "            if view_cfg['extent']:\n",
    "                lon_min, lon_max, lat_min, lat_max = view_cfg['extent']\n",
    "                # Use diff’s coordinates, not lon_ref/lat_ref\n",
    "                lat_grid, lon_grid = xr.broadcast(diff['lat'], diff['lon'])\n",
    "                spatial_mask = ((lat_grid >= lat_min) & (lat_grid <= lat_max) &\n",
    "                                (lon_grid >= lon_min) & (lon_grid <= lon_max))\n",
    "                diff_masked = diff.where(spatial_mask)\n",
    "                weights_masked = weights_2d.where(spatial_mask)\n",
    "                print(\"masked weighting\")\n",
    "            else:\n",
    "                diff_masked = diff\n",
    "                weights_masked = weights_2d\n",
    "\n",
    "            bias = diff_masked.weighted(weights_masked).mean(dim=['lat', 'lon'], skipna=True)\n",
    "            rmse = ((diff_masked**2).weighted(weights_masked).mean(dim=['lat', 'lon'], skipna=True))**0.5\n",
    "\n",
    "            ax.text(0.95,0.05,f\"Bias = {bias.values:.2f}\\nRMSE={rmse.values:.2f}\",transform=ax.transAxes,fontsize=9,va=\"bottom\",ha=\"right\",bbox=dict(boxstyle=\"round,pad=0.3\",facecolor=\"white\",alpha=0.7))\n",
    "  \n",
    "        # Shared colorbar at bottom\n",
    "        cbar_ax = fig.add_axes([0.3, 0.06, 0.4, 0.02])\n",
    "        cbar = fig.colorbar(mesh, cax=cbar_ax, orientation='horizontal')\n",
    "        cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "        fig.suptitle(f\"{varname} [{model_ds[var.varname].units}]:Differences Relative to {shorttitle[ref_id]}, {view_name.capitalize()} View\", fontsize=14)\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{varname}.{view_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea69a7b-b58f-4b61-8f8f-5cd229c69791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# spatial map (global, arctic, antarctic)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"cartopy.io\")\n",
    "\n",
    "views = {\n",
    "    \"global\": {\n",
    "        \"proj\": ccrs.Robinson(central_longitude=-180),\n",
    "        \"extent\": None\n",
    "    },\n",
    "    \"arctic\": {\n",
    "        \"proj\": ccrs.NorthPolarStereo(),\n",
    "        \"extent\": [-180, 180, 60, 90]\n",
    "    },\n",
    "    \"antarctic\": {\n",
    "        \"proj\": ccrs.SouthPolarStereo(),\n",
    "        \"extent\": [-180, 180, -90, -60]\n",
    "    }\n",
    "}\n",
    "\n",
    "coastline = cfeature.NaturalEarthFeature(\n",
    "    category='physical', name='coastline',\n",
    "    scale='110m', facecolor='none')\n",
    "\n",
    "\n",
    "for var in variables_plot:\n",
    "\n",
    "    # Reference data and grid\n",
    "    if var in var_rad:\n",
    "        varname = f\"{var}_cld\"\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    ref_ds = groups[ref_id].datasets[var]\n",
    "    ref_data = ds_ceres[varname].mean(dim='time')\n",
    "    lon_ref = ref_ds['lon']\n",
    "    lat_ref = ref_ds['lat']\n",
    "\n",
    "    # Precompute all differences on the reference grid once\n",
    "    all_diffs = []\n",
    "    for group in groups:\n",
    "        model_ds = group.datasets[var]\n",
    "        model_data = model_ds[varname].mean(dim='time')\n",
    "        try:\n",
    "            # Regrid to reference grid\n",
    "            model_interp = model_data.interp(lon=lon_ref, lat=lat_ref)\n",
    "            diff = model_interp - ref_data\n",
    "            all_diffs.append(diff)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Interpolation failed for {group.name}: {e}\")\n",
    "            all_diffs.append(None)\n",
    "\n",
    "    # Prepare color scale based on all diffs\n",
    "    valid_diffs = [d for d in all_diffs if d is not None and np.any(np.isfinite(d.values))]\n",
    "    if not valid_diffs:\n",
    "        print(f\"[Warning] No valid data for {var.varname}. Skipping plots.\")\n",
    "        continue\n",
    "\n",
    "    all_values = np.concatenate([d.values.flatten() for d in valid_diffs])\n",
    "    if np.percentile(all_values,95) * np.percentile(all_values,5) <0:\n",
    "        vmax = np.percentile(abs(all_values),95)\n",
    "        vmin = -vmax\n",
    "    else:\n",
    "        vmax = max([0,np.percentile(all_values,95)])\n",
    "        vmin = min([0,np.percentile(all_values,5)])\n",
    "        \n",
    "    cmap = 'RdBu_r'\n",
    "\n",
    "    for view_name, view_cfg in views.items():\n",
    "        fig, axs = plt.subplots(2,3, figsize=(14, 8),\n",
    "                                subplot_kw={'projection': view_cfg['proj']})\n",
    "        fig.subplots_adjust(wspace=0.05, hspace=0.15, top=0.9, bottom=0.1)\n",
    "    \n",
    "        for n, diff in enumerate(all_diffs):\n",
    "            row, col = divmod(n, 3)\n",
    "            ax = axs[row, col]\n",
    "    \n",
    "            if diff is None or not np.any(np.isfinite(diff.values)):\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            lat_weights = np.cos(np.deg2rad(model_ds['lat']))\n",
    "            lat_weights.name = \"weights\"\n",
    "            # Expand lat_weights to 2D (lat, lon) by broadcasting\n",
    "            weights_2d = xr.broadcast(lat_weights, model_ds['lon'])[0]\n",
    "            # Apply weights and compute mean\n",
    "\n",
    "            mesh = ax.pcolormesh(lon_ref, lat_ref, diff,\n",
    "                                 vmin=vmin, vmax=vmax,\n",
    "                                 transform=ccrs.PlateCarree(),\n",
    "                                 cmap=cmap, shading=\"nearest\")\n",
    "            ax.set_title(f\"({chr(97 + n)}) {shorttitle[n]} – CERES EBAF\", fontsize=11)\n",
    "    \n",
    "            ax.coastlines()\n",
    "            if view_cfg['extent']:\n",
    "                ax.set_extent(view_cfg['extent'], crs=ccrs.PlateCarree())\n",
    "            else:\n",
    "                ax.set_global()\n",
    "    \n",
    "            if isinstance(view_cfg['proj'], (ccrs.NorthPolarStereo, ccrs.SouthPolarStereo)):\n",
    "                # Add circular boundary to polar plots\n",
    "                theta = np.linspace(0, 2 * np.pi, 100)\n",
    "                center = np.array([0.5, 0.5])\n",
    "                radius = 0.5\n",
    "                verts = np.vstack([np.sin(theta), np.cos(theta)]).T * radius + center\n",
    "                circle_path = Path(verts)\n",
    "                ax.set_boundary(circle_path, transform=ax.transAxes)\n",
    "            if view_cfg['extent']:\n",
    "                lon_min, lon_max, lat_min, lat_max = view_cfg['extent']\n",
    "                lat_grid, lon_grid = xr.broadcast(lat_ref, lon_ref)\n",
    "                spatial_mask = ((lat_grid >= lat_min) & (lat_grid <= lat_max) &\n",
    "                               (lon_grid >= lon_min) & (lon_grid <= lon_max))\n",
    "                diff_masked = diff.where(spatial_mask)\n",
    "                weights_masked = weights_2d.where(spatial_mask)\n",
    "                weights_masked = weights_masked.fillna(0)\n",
    "            else:\n",
    "                diff_masked = diff\n",
    "                weights_masked = weights_2d\n",
    "\n",
    "            bias = diff_masked.weighted(weights_masked).mean(dim=['lat', 'lon'], skipna=True)\n",
    "            rmse = ((diff_masked**2).weighted(weights_masked).mean(dim=['lat', 'lon'], skipna=True))**0.5\n",
    "\n",
    "            ax.text(0.95,0.05,f\"Bias = {bias.values:.2f}\\nRMSE={rmse.values:.2f}\",transform=ax.transAxes,fontsize=9,va=\"bottom\",ha=\"right\",bbox=dict(boxstyle=\"round,pad=0.3\",facecolor=\"white\",alpha=0.7))\n",
    "  \n",
    "        # Shared colorbar at bottom\n",
    "        cbar_ax = fig.add_axes([0.3, 0.06, 0.4, 0.02])\n",
    "        cbar = fig.colorbar(mesh, cax=cbar_ax, orientation='horizontal')\n",
    "        cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "        fig.suptitle(f\"{varname} [{model_ds[var.varname].units}]:Differences Relative to CERES EBAF v4.2.1, {view_name.capitalize()} View\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f\"{varname}.{view_name}.obs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c9fa6-f159-4692-b90c-c62b635fccac",
   "metadata": {},
   "source": [
    "\n",
    "for var in variables:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    fig.subplots_adjust(top=0.95, bottom=0.1, left=0.1, right=0.95)\n",
    "\n",
    "    for group in groups:\n",
    "        ds = group.datasets[var]\n",
    "        ax.plot(ds['lat'], ds[var.varname].mean(dim='time').mean(dim='lon'), label=ds.title)\n",
    "        \n",
    "    ax.set_title(f\"Zonal Mean, {var.varname} [{ds[var.varname].units}]\", fontsize=16)\n",
    "    ax.set_xlabel(\"Latitude\")\n",
    "    ax.set_ylabel(f\"{var} [{ds[var.varname].units}]\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86724b4c-cb50-48f3-a10d-cf981c58a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Modis Data\n",
    "root = '/archive/Huan.Guo/work/obs/CFMIP-OBS/MODIS/MCD06COSP_D3_MODIS/'\n",
    "#fname = f'{root}/MCD06COSP_D3_MODIS_2008_Ann.nc'\n",
    "fname = f'{root}/MCD06COSP_D3_MODIS_2002To2023_Ann.nc'\n",
    "\n",
    "MODIS_grps = xr.open_dataset(fname)\n",
    "for group in MODIS_grps:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c2a8b-d672-452c-bed5-95049854542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"/work/rjk/data/CERES/EBAF-All/CERES_EBAF_Ed4.2.1_Subset_200003-202412.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714cd75-28ec-40f8-a783-0e02474f8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation data regrid\n",
    "\n",
    "import xarray as xr\n",
    "from cosp_lib import cal_gbl_mean\n",
    "import xesmf as xe\n",
    "# load observations, to be added\n",
    "cldfrac_obs_raw = MODIS_tau_grp['JHisto_vs_Cloud_Top_Pressure'] \\\n",
    "    .sum(dim=[\"jhisto_cloud_optical_thickness_total_7\", \"jhisto_cloud_top_pressure_7\"]) \\\n",
    "    .squeeze()\n",
    "\n",
    "for group in diag.groups:\n",
    "    target_grid = xr.Dataset({\n",
    "        'lat': (['lat'], group.datasets[diag.variables[0]]['lat'].values),\n",
    "        'lon': (['lon'], group.datasets[diag.variables[0]]['lon'].values),\n",
    "    })\n",
    "    regridder = xe.Regridder(cldfrac_obs_raw, target_grid, method='bilinear', periodic=True)\n",
    "\n",
    "    var_names = [v.name for v in group.datasets.keys()]\n",
    "    print(var_names)\n",
    "    \n",
    "    cldfrac_sum = sum([group.datasets[v] for v in var_names if v.startswith('tauctpmodis_')])\n",
    "    # Assign to 'cldfrac' and process\n",
    "    group.datasets['cldfrac'] = cldfrac_sum.sum(dim='modistauindx').squeeze()\n",
    "\n",
    "    group.datasets['cldfrac'].attrs['units'] = '%'\n",
    "    group.datasets['cldfrac_obs'] = regridder(cldfrac_obs_raw)\n",
    "    for var in vars:\n",
    "        #group.group.datasets[0][var] = group.group.datasets[0][var] .where(group.group.datasets[0][var] != 0)\n",
    "        # Unit conversion\n",
    "        units = group.datasets[var].attrs.get(\"units\", \"\")\n",
    "        if units == \"m\":\n",
    "            group.datasets[var].values = group.datasets[var].values * 1e6  # use 1e6, not 10^6\n",
    "            group.datasets[var].attrs[\"units\"] = \"micron\"\n",
    "        elif units == \"Pa\":\n",
    "            group.datasets[var].values = group.datasets[var].values / 100.0\n",
    "            group.datasets[var].attrs[\"units\"] = \"hPa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599044e-cb02-470b-b487-5b7bc484122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation data regrid\n",
    "\n",
    "import xarray as xr\n",
    "from cosp_lib import cal_gbl_mean\n",
    "import xesmf as xe\n",
    "# load observations, to be added\n",
    "cldfrac_obs_raw = MODIS_tau_grp['JHisto_vs_Cloud_Top_Pressure'] \\\n",
    "    .sum(dim=[\"jhisto_cloud_optical_thickness_total_7\", \"jhisto_cloud_top_pressure_7\"]) \\\n",
    "    .squeeze()\n",
    "\n",
    "for group in diag.groups:\n",
    "    target_grid = xr.Dataset({\n",
    "        'lat': (['lat'], group.datasets[diag.variables[0]]['lat'].values),\n",
    "        'lon': (['lon'], group.datasets[diag.variables[0]]['lon'].values),\n",
    "    })\n",
    "    regridder = xe.Regridder(cldfrac_obs_raw, target_grid, method='bilinear', periodic=True)\n",
    "\n",
    "    var_names = [v.name for v in group.datasets.keys()]\n",
    "    print(var_names)\n",
    "    \n",
    "    cldfrac_sum = sum([group.datasets[v] for v in var_names if v.startswith('tauctpmodis_')])\n",
    "    # Assign to 'cldfrac' and process\n",
    "    group.datasets['cldfrac'] = cldfrac_sum.sum(dim='modistauindx').squeeze()\n",
    "\n",
    "    group.datasets['cldfrac'].attrs['units'] = '%'\n",
    "    group.datasets['cldfrac_obs'] = regridder(cldfrac_obs_raw)\n",
    "    for var in vars:\n",
    "        #group.group.datasets[0][var] = group.group.datasets[0][var] .where(group.group.datasets[0][var] != 0)\n",
    "        # Unit conversion\n",
    "        units = group.datasets[var].attrs.get(\"units\", \"\")\n",
    "        if units == \"m\":\n",
    "            group.datasets[var].values = group.datasets[var].values * 1e6  # use 1e6, not 10^6\n",
    "            group.datasets[var].attrs[\"units\"] = \"micron\"\n",
    "        elif units == \"Pa\":\n",
    "            group.datasets[var].values = group.datasets[var].values / 100.0\n",
    "            group.datasets[var].attrs[\"units\"] = \"hPa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb116b0f-cf7e-4dda-b5e2-b37e2e763ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be added: comparisons with observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1ddb4-aa9b-4647-8b9b-1cf421ae869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag.write_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00330c6-e518-46b9-b7e2-b27faa9c5df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
